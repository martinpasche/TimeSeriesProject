{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ARDL\n",
    "- VAR\n",
    "- ECM Error correction model\n",
    "- SVAR structural vector auto-regression\n",
    "- GMM with constraints\n",
    "- CVAR co integrated var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight. SARIMA model can work with data that is I(2), meanwhile the rest of the models can't, except for VARI, Vector autoregression for integrated series, and CVAR but a modified version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARDL Auto-regressive distributed lag model\n",
    "\n",
    "The model is a econometric model used to analyze the dynamic relationship between dependent variable and one or more explanatory variables, while incorporating both their current and lagged values. It is particulary useful when variables are a mix of I(0), I(1) (non-stationary) but not I(2) variables. \n",
    "\n",
    "1. Formula: \n",
    "\n",
    "$$Y_t = c + ∑(ϕ_i Y_{t-i}) + ∑(∑(β_{j,m} X_{j,t-m})) + ε_t$$\n",
    "\n",
    "a single explanatory variable $X_t$, ARDL(p,q) model is:\n",
    "\n",
    "$$Y_t = c + ∑(ϕ_i Y_{t-i}) + ∑(β_m X_{t-m}) + ε_t$$\n",
    "\n",
    "2. Intuition\n",
    "\n",
    "    1. Combines lagged effects\n",
    "    2. Short term and long term relationship: short in lagged terms and long-term from equilibrium relationship between variables\n",
    "    3. Flexibility with mixed integration orders\n",
    "    4. Error correction mechanism\n",
    "    \n",
    "3. Steps\n",
    "\n",
    "    1. Check order of integration. non $I(2)$\n",
    "    2. Lag selection: AIC, BIC, HQIC\n",
    "    3. Estimate the model\n",
    "    4. Test for cointegration. Bounds test, check for presence of long-term relationship\n",
    "    5. Transform into ECM (if cointegration exists): rewrite the model in ECM\n",
    "    \n",
    "**Assumptions**\n",
    "\n",
    "1. Stationary residuals\n",
    "2. No $I(2)$ variables. That must be $I(0)$ or $I(1)$\n",
    "3. Linear relationship between variables\n",
    "4. Exogeneity of explanatory variables\n",
    "5. Sufficient Data length\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "1. Dependent on lag selection\n",
    "2. Non-linear relationships\n",
    "3. Bound test limitations (not robust for small samples)\n",
    "4. Model complexity\n",
    "5. Endogeneity: weak exogeneity of regressor.\n",
    "\n",
    "**Applications**\n",
    "\n",
    "1. Finance \n",
    "    1. Asset pricing.\n",
    "    2. Volatility modeling\n",
    "    3. Exchange rates\n",
    "    \n",
    "2. Macroeconomics\n",
    "    1. Monetary policy\n",
    "    2. Trade analysis\n",
    "    3. Consumption and saving\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR\n",
    "\n",
    "statistical use to capture linear interdependencies among multiple time series. All varaibles are endogenous. Models dynamics between them.\n",
    "\n",
    "$$ Y_t = c + \\sum_{i=1}^{p} A_i Y_{t-i} + \\epsilon_t $$\n",
    "\n",
    "where is term is a vector or a matrix.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "1. Stationarity\n",
    "2. Linearity\n",
    "3. No multicollinearity\n",
    "4. White noise residuals\n",
    "5. Sufficient lag selection.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "1. High dimensionality\n",
    "2. Stationarity\n",
    "3. No structural interpretability\n",
    "4. Overfitting risk\n",
    "5. Causality. (it only shows associations)\n",
    "\n",
    "**Applications**\n",
    "\n",
    "1. Multivariate time series analysis\n",
    "2. Forecasting\n",
    "3. Shock analysis (impulse response functions)\n",
    "4. Macroeconomic systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECM error correlation model\n",
    "\n",
    "Used to model dynamic relationships between time series while explicitly taking into account the long-run equilibrium relationships between them. It is a special case of VAR. It is employed when the variables are cointegrated.(i.e. they have a stable, long-term relationship despite being non-stationary individually).\n",
    "\n",
    "There is only one target variable. It focuses in co-integration. there is no symmetry in variables.\n",
    "\n",
    "$$ΔY_t = α + βΔX_t + γEC_t-1 + ε_t$$\n",
    "\n",
    "$$EC_{t-1} = Y_{t-1} - \\beta_0 - \\beta_1X_{t-1}$$\n",
    "\n",
    "EC measures how far the system is from the equilibrium relationship.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "1. Cointegration: variables are non-stationary I(1) but have a stable long-term relationship.\n",
    "2. Stationarity differences: first difference is stationary.\n",
    "3. Linearity\n",
    "4. White noise error\n",
    "5. Exogeneity: $X_t$ is weakly exogenous\n",
    "\n",
    "**Limitations** \n",
    "\n",
    "1. Assumes cointegration\n",
    "2. Linearity\n",
    "3. Limited short-term modeling\n",
    "4. sensitivity to specifications\n",
    "5. Small sample bias: ecm models can suffer from inefficiency and instability in small datasets\n",
    "\n",
    "**Applications**\n",
    "\n",
    "1. Macroeconomics\n",
    "2. Finance. stock price adjustments.\n",
    "3. Energy economics\n",
    "4. Policy analysis. short term shocs affect long term economic\n",
    "5. international trade\n",
    "\n",
    "\n",
    "**How to identify cointegration** \n",
    "\n",
    "There are statistical tests. They measures long term relationships between non-stationary variables.\n",
    "\n",
    "1. Engle-Granger test\n",
    "    1. Uses OLS to estimate relationships.\n",
    "    2. Test for stationarity of residuals.\n",
    "  \n",
    "2. Johansen test\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVAR: Structural vector auto-regression\n",
    "\n",
    "extension of VAR model. Incorporates structural information based on economic or theoretical assumptions to identify casual relationships between variables. Unlike VAR, which models associations, SVAR seeks to establish cause-and-effect dynamics. This model uses structual constraints to infer causality\n",
    "\n",
    "$$A Y_t = c + ∑ (B_i Y_{t-i}) + ε_t$$\n",
    "\n",
    "A: structural impact. relationships between variables\n",
    "\n",
    "VAR is $Y_t = c + ∑ (Φ_i Y_{t-i}) + e_t$\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "1. Identifiability: To identify $A$ and $B_i$ the number of restrictions on $A$ must be sufficient.\n",
    "2. Structural shocks: $ε_t$ are uncorrelated and have economic meaning (demand shock, supply shock)\n",
    "3. Stationarity\n",
    "4. Linearity\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "1. Identifiability: very subjective\n",
    "2. High dimensions: higher dimensions, exponentially more restrictions\n",
    "3. Stationarity\n",
    "4. Overfitting\n",
    "5. Linear\n",
    "\n",
    "**Applications**\n",
    "\n",
    "1. Macroeconomics\n",
    "2. Finance: study impact of finantial shocks, credit speads or market volatility\n",
    "3. Energy economics\n",
    "4. International trade\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM generalized method of moments\n",
    "\n",
    "Econometric technique used when standard assumsptions of OLS or MLE are violated. It relies on moment condidions derivated from economic theory or data properties to estimate parameters.\n",
    "\n",
    "1. The model is calculated by minimizing the difference between the sample moments and the model moments.\n",
    "\n",
    "$$ θ̂ = argmin_θ g(θ)' W g(θ)$$\n",
    "\n",
    "$g(θ)$ is the vector of moment conditions. $g(\\theta) = \\frac{1}{n} \\sum^n_{i=1} z_i h(x_i, \\theta) $\n",
    "\n",
    "- $h(x_i, \\theta)$ is the moment function, representing theoretical relationships\n",
    "\n",
    "$W$ is a positive definite weighting matrix.\n",
    "\n",
    "\n",
    "2. Steps to estimate parameters using GMM\n",
    "\n",
    "    1. Define moment conditions. for example $E[h(x_i, \\theta)] = 0$, with $h(x_i, \\theta)= x_i (y_i - x_i' \\theta)$ this ensure the residuals $(y_i - x_i' \\theta)$ are uncorrelated with $x_i$\n",
    "    2. Choose a weighting matrix $W$\n",
    "    3. Optimize\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "1. Moment conditions are valid\n",
    "2. Weighting matrix is positive definite\n",
    "3. Instrument relevance. (Instrumental variables are correlated with the endogenous variables but uncorrelated with the error term)\n",
    "4. Exogeneity\n",
    "5. Stationarity\n",
    "6. Sufficient sample size\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "1. Sensitive to instrument choice\n",
    "2. Overfitting\n",
    "3. Finite-sample problem\n",
    "4. Misspecified moment conditions\n",
    "5. Computational complexity\n",
    "\n",
    "**Applications**\n",
    "\n",
    "1. Finance: asset pricing, risk-return relationship, volatility modeling\n",
    "2. Macroeconomics: estimating DSGE models (dynamic stochastic general equilibrium), phillips curve estimation, policy analysis.\n",
    "\n",
    "| **Feature**            | **OLS**                      | **MLE**                     | **GMM**                     |\n",
    "|-------------------------|------------------------------|-----------------------------|-----------------------------|\n",
    "| **Moment Conditions**   | Implicit                    | Likelihood-based            | Explicitly defined          |\n",
    "| **Endogeneity**         | Cannot handle               | Requires strong assumptions | Handles via instruments     |\n",
    "| **Efficiency**          | Efficient if assumptions hold | Efficient under correct model | Asymptotically efficient    |\n",
    "| **Robustness**          | Sensitive to outliers       | Sensitive to distribution   | Robust to some misspecifications |\n",
    "| **Applications**        | Linear regression           | Structural models           | Wide-ranging, incl. finance |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVAR: Co-integrated vector autoregression\n",
    "\n",
    "Is an extension of VAR designed for non-stationary time series that are cointegrated. It combines the short-term dynamic of VAR with long-term equilibrium relationships between variables (cointegration).\n",
    "\n",
    "1. The CVAR model is often represented as a Vector Error Correction Model (VECM), which is derived from the VAR model.\n",
    "\n",
    "$$ΔY_t = Π Y_{t-1} + ∑(Γ_i ΔY_{t-i}) + ε_t$$\n",
    "\n",
    "- $ΔY_t$: first difference of endogenous variables\n",
    "- $\\Pi$ long term impact matrix, captures cointegration relationships.\n",
    "- $Γ_i$ short-term adjustement matrix, capturing dynamic relationships in first differences.\n",
    "\n",
    "2. Cointegration relationship\n",
    "\n",
    "- Matrix $\\Pi$ can be decomposed as: $\\Pi = αβ'$, where $α$ and $β$ are matrices of cointegration vectors.\n",
    "- Short-term dynamic: captured by $Γ_i$ matrix.\n",
    "- Error correction term\n",
    "\n",
    "3. Intuition\n",
    "\n",
    "- Long-Term Equilibrium: CVAR assumes that while individual time series may be non-stationary, linear combinations of them are stationary. These stationary combinations define the long-term relationships.\n",
    "- Short-Term Adjustments: The model captures how deviations from long-term equilibrium influence short-term dynamics.\n",
    "- Combination of VAR and Cointegration: CVAR combines the strengths of VAR for short-term analysis with cointegration for long-term analysis.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "1. Cointegration: Variables are non-stationary but have stable long-term relationships. Johansen test. \n",
    "2. Stationarity differences: First difference is stationary.\n",
    "3. Linearity\n",
    "4. White noise error\n",
    "5. Exogeneity: the model assumes no significant external shocks that systematically bias relationships\n",
    "6. Sufficient sample size\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "1. Complexity\n",
    "2. Sensitivity to specifications\n",
    "3. Stationary assumptions\n",
    "4. Linear assumption\n",
    "5. Data intensive: estimation requires substantial data, specially when working with many variables.\n",
    "\n",
    "**Applications**\n",
    "\n",
    "1. Finance\n",
    "    1. Asset pricing\n",
    "    2. Exchange rates\n",
    "    3. Interest rates\n",
    "    \n",
    "2. Macroeconomics\n",
    "    1. Policy analysis\n",
    "    2. Economic forecasting\n",
    "    3. Inflation dynamics\n",
    "    \n",
    "\n",
    "\n",
    "| **Feature**                | **VAR**                                  | **SVAR**                                     | **CVAR**                                       |\n",
    "|----------------------------|------------------------------------------|---------------------------------------------|-----------------------------------------------|\n",
    "| **Stationarity**            | Requires stationarity or differencing.  | Requires stationarity or differencing.      | Handles non-stationary but cointegrated data. |\n",
    "| **Long-Term Relationships** | Not modeled.                            | Not modeled explicitly.                     | Explicitly includes cointegration (via \\( Π \\)). |\n",
    "| **Causality**               | No causal interpretation.               | Causal relationships inferred via structure.| Cointegration relationships provide economic meaning. |\n",
    "| **Model Structure**         | Simple lagged dynamics.                 | Adds contemporaneous structural constraints.| Combines VAR with error correction (VECM).    |\n",
    "| **Applications**            | Short-term forecasting.                 | Policy analysis and causal inference.       | Long-term equilibrium and short-term dynamics.|\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo ARDL\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.ardl import ARDL\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = df['Comptes a terme et livrets ordinaires, actif des menages, encours trimestriel']\n",
    "X = df[['Taux de rémunération annuel des livrets ordinaires']]\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "max_lag_y = 5\n",
    "max_lag_X = [1, 3]\n",
    "\n",
    "model = ARDL(y, max_lag_y, X, max_lag_X)\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y.iloc[max_lag_y:], label='Comptes a terme et livrets ordinaires')\n",
    "plt.plot(df.iloc[max_lag_y:].index, result.fittedvalues, label='Fitted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Encours trimestriel')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"ARDL Model: Comptes a terme et livrets ordinaires vs. Taux de rémunération annuel\")\n",
    "plt.show()\n",
    "\n",
    "def backtesting_ARDL(y, X, lag_y, lag_X, test_size=24, trend='c'):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from statsmodels.tsa.ardl import ARDL\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "    X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "    \n",
    "    # Fit the ARDL model\n",
    "    model = ARDL(y_train, lag_y, X_train, lag_X, trend=trend)\n",
    "    result = model.fit()\n",
    "    \n",
    "    # Prepare the exogenous variables for prediction (ensure lags are correct)\n",
    "    X_with_lags = X.copy()\n",
    "    X_with_lags.index = y.index  # Ensure alignment of indice\n",
    "    \n",
    "    # Predict the test set\n",
    "    y_pred = result.forecast(steps = test_size, exog=X_with_lags)\n",
    "    \n",
    "    # Calculate the MAPE\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    # Calculate the MSE\n",
    "    mse = np.mean((y_test - y_pred)**2)\n",
    "    \n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}%\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    \n",
    "    return y_pred\n",
    "    \n",
    "\n",
    "\n",
    "y_pred = backtesting_ARDL(y, X, max_lag_y, max_lag_X, test_size = 24)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y, label='Comptes a terme et livrets ordinaires')\n",
    "plt.plot(y_pred, label='Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Encours trimestriel')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
